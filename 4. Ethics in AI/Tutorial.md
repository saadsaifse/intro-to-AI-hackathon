# Ethics in Artificial Intelligence

```
Einav Grinberg, Muhammad Saad Saif, Anna Formaniuk
```

## Overview

### Objective

During this tutorial, readers will explore the current impact of AI in our society as well as future implications.

```
● Ethics Definition - 2 minutes
● The ethical dilemma of self-driving cars by Patrick Lin  - 10 minutes
● AI Bias - 5 minutes
● Fake AI - 5 minutes
● Privacy & Surveillance - 8 minutes
● AI and Employment - 5 minutes
● Task - 10-15 minutes
```

---

## Ethics Definition

### Merriam-Webster Dictionary 
*<b>Ethics</b> - The discipline dealing with what is good and bad and with moral duty and obligation. A set of moral principles governing the behavior or actions of an individual or a group.*

### Oxford Dictionary
*<b>Ethics</b> - The branch of knowledge that deals with moral principles. Moral principles that govern a person's behaviour or the conducting of an activity.* 

---

## The ethical dilemma of self-driving cars by Patrick Lin

Patrick Lin is the director of the Ethics + Emerging Sciences Group, based at California Polytechnic State University, San Luis Obispo, where he is also a philosophy professor. In the TedEd link before you, Professor Lin discusses the ethics of self-driving cars. 

<b>Watch</b> the video and <b>Think</b> while answering the questions, for more information you can <b>Dig Deeper</b> and read additional articles.  
TedEd link: https://ed.ted.com/on/ZqB0pyBs 

---

## AI Bias

<img src="https://blogs.gartner.com/anthony_bradley/files/2020/01/4-Stages-of-Ethical-AI.png" width="500">


In his article J. Bradley (2020) describes four stages relevant to AI bias; real-world bias, data bias, algorithm bias, and business bias.
1. **Real-world bias** involves actual bias in real-world situations such as gender bias, name bias, or beauty bias. 
For example, Name bias is the tendency people have to judge and prefer people with certain types of names. This may occur when reviewing your future classmates and some names will appear to you as foreign or strange. 
2. **Data bias** happens when the data accurately reflects the real world. If the data is reflective of the real-world it will also reflect the biases that occur in the real world. 
3. **Algorithm bias**, an algorithm is a set of rules that precisely defines a sequence of operations. These rules are defined by humans and operated by machines, algorithm bias is an outcome of real-world bias that humans have. 
For example: when a job application filtering tool is trained on decisions made by humans, the machine learning algorithm may learn to discriminate against women or individuals with a certain ethnic background.
4. **Bussiness bias** represents how businesses act upon the data/AI for business benefit. Most businesses will be bias based on relevant criteria that determines a good prospective customer, storefront geography, job candidate, product investment, etc. 

This cycle presented in the figure shows how each bias affects the other in a cause and effect flow.

---

## Fake AI

AI "faking" technologies make what once could have been regarded as reliable evidence into unreliable evidence. This is already happening to digital photos, sound recordings, and videos.

```
Examples: 
● People can be put in places they never visited with people they never met by using photoshop.
● AI can change the way one looks by 'slimming' them down in before and after pictures advertising a  diet pill.
```
**Check out these "Fake" AI tools:**

[Face2Face](https://www.youtube.com/watch?v=ohmajJTcpNk) - a system capable of identifying the facial expressions of a person and putting them on another person’s face in a Youtube video.  
[Lyrebird](https://www.descript.com/overdub?lyrebird=true) - a tool for automatic imitation of a person’s voice from a few minutes of sample recording.


---

## Privacy & Surveillance

As technology has advanced, how privacy is protected and violated has changed with it. AI leads to new kinds of threats to our privacy, which may be harder to avoid. AI can conduct facial analysis, skin texture analysis, speech recognition, and emotion recognition. All without permission or cooperation from the individual.

**An example can be using data analysis to identify individuals:**  

In China, the belief is that surveillance with Facial Recognition is essential to law enforcement and public safety. Even in the U.S.A facial recognition for law enforcement is also routinely used everywhere, except in its tech capital -  San Francisco.

<img src="https://media1.s-nbcnews.com/j/newscms/2019_19/2847376/190506-face-recognition-small-crimes-main-kh_af209030008a39ab916bb89809b55c04.fit-2000w.jpg" width="500">

**Read the following articles, and write which approach you would endorse if you were the mayor of the city you currently live in and try to explain why.**

* [One Month, 500,000 Face Scans: How China Is Using A.I. to Profile a Minority](https://www.nytimes.com/2019/04/14/technology/china-surveillance-artificial-intelligence-racial-profiling.html)
* [How facial recognition became a routine policing tool in America](https://www.nbcnews.com/news/us-news/how-facial-recognition-became-routine-policing-tool-america-n1004251)
* [San Francisco’s facial recognition technology ban, explained](https://www.vox.com/recode/2019/5/14/18623897/san-francisco-facial-recognition-ban-explained)

---

## AI and Employment 

Since the mid 20th century, technological development has lead to a period of extraordinary progress in automation. It seems clear that AI and robotics will lead to significant gains in productivity. Productivity gains through automation typically mean that a company or organization needs fewer humans for the same output. With AI and robotics, there is even less need for many kinds of dull, repetitive work.

A study by Carl Benedikt Frey and Michael Osborne (2013) of Oxford University used a machine-learning algorithm to assess how easily 702 different kinds of jobs in America could be automated. The results concluded that 47% of jobs in America could be done by machines over the next decade or two.

The following two charts were published in 2018 by the OECD in a study (based on the study by Carl Benedikt Frey and Michael Osborne in 2013) that estimates the risk of automation for jobs based on 32 OECD countries that have participated in the Survey of Adult Skills (PIAAC).

<img src="https://www.economist.com/img/b/1280/969/90/sites/default/files/20180428_WOC328.png" width="500">

For the overall sample of 32 countries, the average job is estimated to have 48% probability of being automated. However, there is a large variation in the degree of automatability across countries. For example, jobs in Slovakia are twice as vulnerable to be automated compared to those in Norway and in Greece and Lithuania the average worker has 57% chance of being automated.

<img src="https://www.economist.com/img/b/1280/915/90/sites/default/files/images/2018/04/blogs/graphic-detail/20180428_woc318_0.png" width="500">

The job types that have the highest probability of becoming automated mostly do not require specific skills or training: food preparation assistants, construction workers, driver, cleaners, and helpers. The industries with a low average probability of being automated are mainly part of the service sector - education, health care, politics, etc.

---

## Task - Implications of AI

Write an essay (minimum 500 words, maximum 800 words) on one of the following topics presented in this tutorial. 
You can use articles to give examples and support your thoughts. 
Please send the essay to us via email in PDF with the chosen topic and your name written on the first page.

```
The topics:

● AI Bias 
● Fake AI 
● Privacy & Surveillance
● AI and Employment 
```

---

## References

```
● A study finds nearly half of jobs are vulnerable to automation. (2018). Retrieved 7 August 2020, from https://www.economist.com/graphic-detail/2018/04/24/a-study-finds-nearly-half-of-jobs-are-vulnerable-to-automation
● Bossmann, J. (2016). Top 9 ethical issues in artificial intelligence. Retrieved 5 August 2020, from https://www.weforum.org/agenda/2016/10/top-10-ethical-issues-in-artificial-intelligence/
● Elements of AI, Helsinki University - https://course.elementsofai.com
● Ethics | Definition of Ethics by Oxford Dictionary on Lexico.com also meaning of Ethics. Retrieved 5 August 2020, from https://www.lexico.com/definition/ethics
● J. Bradley, A. (2020). 4 Stages of Ethical AI: Algorithmic Bias is Not the Problem but Part of the Solution - Anthony Bradley. Retrieved 5 August 2020, from https://blogs.gartner.com/anthony_bradley/2020/01/15/4-stages-ethical-ai-algorithmic-bias-not-problem-part-solution/
● Nalini, B. (2019). The Hitchhiker’s Guide to AI Ethics. Retrieved 5 August 2020, from https://towardsdatascience.com/ethics-of-ai-a-comprehensive-primer-1bfd039124b0
● Nedelkoska, L. and G. Quintini (2018), "Automation, skills use and training", OECD Social, Employment and Migration Working Papers, No. 202, OECD Publishing, Paris, https://doi.org/10.1787/2e2f4eea-en
● Merriam-Webster. (n.d.). Ethic. In Merriam-Webster.com dictionary. Retrieved August 5, 2020, from https://www.merriam-webster.com/dictionary/ethic
● Müller, Vincent C., "Ethics of Artificial Intelligence and Robotics", The Stanford Encyclopedia of Philosophy (Fall 2020 Edition), Edward N. Zalta (ed.), forthcoming URL = <https://plato.stanford.edu/archives/fall2020/entries/ethics-ai/>. 
```

